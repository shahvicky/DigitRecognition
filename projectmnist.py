# -*- coding: utf-8 -*-
"""ProjectMnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y02uaIJh3M49fzn-pvzRNZdpGYHRC3gY
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
from sklearn.preprocessing import label_binarize
from sklearn import model_selection as cross_validation
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from scipy import interp
from itertools import cycle

"""The training data and testing data downloaded from [Kaggle](https://www.kaggle.com/c/digit-recognizer) has been uploaded to github and the link of github is used to fetch data in dataframe object (df)."""

df = pd.read_csv('https://raw.githubusercontent.com/96sonu/Digit-Recognition/master/train.csv')

"""The testing data from kaggle is used in same way as training data. The label for testing data is not provided. The output needs to submitted online to check the accuracy of model. Here is the link of my [account](https://www.kaggle.com/sonu96/competitions) in kaggle.

For the project we have divided the training data and used a part as testing data to display accuracy, Area under ROC and ROC Curve with graphical representation of loss and accuracy.
"""

kaggle_test_set = pd.read_csv('https://raw.githubusercontent.com/96sonu/Digit-Recognition/master/test.csv')
kaggle_test_set = np.array(kaggle_test_set).reshape(kaggle_test_set.shape[0], 28, 28,1)
kaggle_test_set = kaggle_test_set.astype('float32')
kaggle_test_set /= 255

"""The training data has 786 pixel values and one label. In below code the pixel columns and label have been seperated. And a copy of test labels have been copied in other variable for calculating accuracy ahead in code."""

train_label = pd.DataFrame(df['label'])
train_columns = df.drop('label', axis = 1)

train_images, test_images, train_label, test_labels = cross_validation.train_test_split(train_columns,train_label,test_size=0.15,random_state=0)
original_test_labels = test_labels

"""In below code how many examples of each digit are available in the training data is calculated."""

image = {}
for i in range(10):
    image[i] = df[df['label'] == i]
    image[i] = image[i].drop('label', axis = 1)
count = 0  
for i in range(0,10):
  print(i ," = ",len(image[i]))
  count = count + len(image[i])
print(count)

"""Training and testing data are reshaped into a 3 dimensional data(28,28,1 - where 1 stands for the channel) from original 2 dimensional(28,28)"""

train_images = np.array(train_images).reshape(train_images.shape[0], 28, 28,1)
test_images = np.array(test_images).reshape(test_images.shape[0], 28, 28,1)
print(np.array(train_images).reshape(train_images.shape[0], 28, 28,1).shape )

"""In below code the preprocessing of the training and testing data is done by converting it to float type and then dividing it by 255 to scale the pixel value between 0 and 1."""

train_images = train_images.astype('float32')
test_images = test_images.astype('float32')
train_images /= 255
test_images /= 255
print('Shape of training data:', train_images.shape)
print('Training samples:', train_images.shape[0])
print('Testing Samples:', test_images.shape[0])

"""In below code the one hot encoding of the all 10 labels is generated for output at CNN."""

train_label = keras.utils.to_categorical(train_label, 10)
test_labels = keras.utils.to_categorical(test_labels, 10)

"""The Sequencial model is generated and convolution layer, maxpool layers and dense layer for output and activation function."""

ConvNet_model = Sequential()
ConvNet_model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=(28,28,1)))
ConvNet_model.add(Conv2D(64, (3, 3), activation='relu'))
ConvNet_model.add(Conv2D(64, (2, 2), activation='relu'))
ConvNet_model.add(MaxPooling2D(pool_size=(2, 2)))
ConvNet_model.add(Dropout(0.25))
ConvNet_model.add(Flatten())
ConvNet_model.add(Dense(128, activation='relu'))
ConvNet_model.add(Dropout(0.25))
ConvNet_model.add(Dense(10, activation='softmax'))

ConvNet_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])

"""The model is trainined at this point with preprocessed training data."""

fashion_train = ConvNet_model.fit(train_images, train_label,batch_size=100,epochs=15,verbose=1,validation_data=(test_images, test_labels))

score = ConvNet_model.evaluate(test_images, test_labels, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

"""Below is the code displaying confusion matrix of the original and predicted output from the model."""

predicted_output = ConvNet_model.predict_classes(test_images)
confusion_matrix(np.argmax(test_labels,axis=1), predicted_output)

ConvNet_model.summary()

"""In below code the label for test dataset of kaggle is predicted the output of which is displayed below."""

kaggle_test_predicted_labels = ConvNet_model.predict_classes(kaggle_test_set)

"""This code generates the output i format to be submitted at kaggle."""

print("ImageId,Label")
count = 1
for x in kaggle_test_predicted_labels:
  print(str(count)+','+str(x))
  count += 1

"""Below is the code for displaying graphical representation of training and validation accuracy and loss at each iteration."""

accuracy = fashion_train.history['acc']
val_accuracy = fashion_train.history['val_acc']
loss = fashion_train.history['loss']
val_loss = fashion_train.history['val_loss']
epochs = range(len(accuracy))
plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

"""Below code outputs the ROC curve, Area under ROC curve."""

y_pred_proba = ConvNet_model.predict_classes(test_images)
#print(y_pred_proba)

auc = metrics.roc_auc_score(test_labels, label_binarize(y_pred_proba.tolist(),classes=[0,1,2,3,4,5,6,7,8,9]))
print("Area Under curve:",auc)
#fpr, tpr, _ = metrics.roc_curve(label_binarize(original_test_labels['label'].tolist(), classes=[0,1,2,3,4,5,6,7,8,9]),  label_binarize(y_pred_proba.tolist(),classes=[0,1,2,3,4,5,6,7,8,9])))

fpr = dict()
tpr = dict()
roc_auc = dict()
classes=[0,1,2,3,4,5,6,7,8,9]
for i in range(0,10):
  
    #print(label_binarize(original_test_labels['label'].tolist(), classes=[0,1,2,3,4,5,6,7,8,9]))
    fpr[i], tpr[i], _ = metrics.roc_curve(label_binarize(original_test_labels['label'].tolist(), classes=[0,1,2,3,4,5,6,7,8,9])[:,i], label_binarize(y_pred_proba.tolist(),classes=[0,1,2,3,4,5,6,7,8,9])[:,i])
    roc_auc[i] = metrics.auc(fpr[i], tpr[i])

#plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
#plt.legend(loc=4)
#plt.show()

# plot ROC curve for a specific class
plt.figure()
lw = 2
plt.plot(fpr[2], tpr[2], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve')
plt.legend(loc="lower right")
plt.show()


# Computing ROC curve,area and micro-average 
fpr["micro"], tpr["micro"], _ = metrics.roc_curve(label_binarize(original_test_labels['label'].tolist(),classes = [0,1,2,3,4,5,6,7,8,9]).ravel(), label_binarize(y_pred_proba.tolist(),classes=[0,1,2,3,4,5,6,7,8,9]).ravel())
roc_auc["micro"] = metrics.auc(fpr["micro"], tpr["micro"])

# Aggregating all FPR
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(0,9)]))

# Then interpolate all ROC curves at this points
mean_tpr = np.zeros_like(all_fpr)
for i in range(0,10):
    mean_tpr += interp(all_fpr, fpr[i], tpr[i])

# Computing AUC by averaging TPR
mean_tpr /= 10

fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = metrics.auc(fpr["macro"], tpr["macro"])

#ROC curve for all classes in one plot
plt.figure()
plt.plot(fpr["micro"], tpr["micro"],
         label='micro-average ROC curve (area = {0:0.2f})'
               ''.format(roc_auc["micro"]),
         color='deeppink', linestyle=':', linewidth=4)

plt.plot(fpr["macro"], tpr["macro"],
         label='macro-average ROC curve (area = {0:0.2f})'
               ''.format(roc_auc["macro"]),
         color='navy', linestyle=':', linewidth=4)

colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
for i, color in zip(range(0,10), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=lw,
             label='ROC curve: class {0} (area = {1:0.2f})'
             ''.format(i, roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=lw)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC for all numbers')
plt.legend(loc="lower right")
plt.show()